{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "# we are querying the datalake via AWS athena using the awswrangler library\n",
    "%pip install awswrangler\n",
    "\n",
    "# auto load the updated external functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import sklearn\n",
    "# import torch\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import awswrangler as wr\n",
    "import sagemaker\n",
    "\n",
    "DISPLAY_INFO = True\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if DISPLAY_INFO:\n",
    "    InteractiveShell.ast_node_interactivity = \"all\" # display results in each line (for debugging)\n",
    "else:\n",
    "    InteractiveShell.ast_node_interactivity = \"none\" # no display\n",
    "    # InteractiveShell.ast_node_interactivity = \"last\" # (default) display results in the last line    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2023, 7, 5, 0, 0, 0)\n",
    "end = datetime(2023, 7, 5, 5, 0, 0)\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_FORMAT_STR = \"%Y-%m-%d %H:00:00\"\n",
    "FILENAME_FORMAT_STR = \"'%Y-%m-%d_%H0000'\"\n",
    "\n",
    "TIME_INTERVAL = 60 * 60 # hour\n",
    "# TIME_INTERVAL = 60 * 60 * 24 # day\n",
    "\n",
    "DATABASE = 'tgao_tmp'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select enabled fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enabled_fields = ['*']\n",
    "enabled_fields_str = ', '.join(enabled_fields)\n",
    "\n",
    "enabled_fields_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2023, 7, 5, 0, 0),\n",
       " datetime.datetime(2023, 7, 5, 1, 0),\n",
       " datetime.datetime(2023, 7, 5, 2, 0),\n",
       " datetime.datetime(2023, 7, 5, 3, 0),\n",
       " datetime.datetime(2023, 7, 5, 4, 0)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_list = [\n",
    "    start + timedelta(hours=x)\n",
    "    for x in range(0, int((end - start).total_seconds() / TIME_INTERVAL))\n",
    "]\n",
    "\n",
    "time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(start_hour, enabled_fields_str='*', enable_query_display=False):\n",
    "    start_hour_str = start_hour.strftime(SQL_FORMAT_STR)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT {enabled_fields_str}\n",
    "    FROM \n",
    "        datalake.imhotep.rjptrainingv1\n",
    "    WHERE \n",
    "        hour = '{start_hour_str}'\n",
    "    \"\"\"\n",
    "\n",
    "    query = f'{query}\\nlimit 5' if DEBUG else query\n",
    "\n",
    "    if enable_query_display:\n",
    "        print(query)\n",
    "\n",
    "    return wr.athena.read_sql_query(query, database=DATABASE, ctas_approach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/partition/'2023-07-05_000000'.parquet\n",
      "\n",
      "    SELECT *\n",
      "    FROM \n",
      "        imhotep_qa.rjpTraining_temp2\n",
      "    WHERE \n",
      "        hour = '2023-07-05 00:00:00'\n",
      "        and is_feedId is not null\n",
      "    limit 5\n",
      "\tRows: 5\n",
      "Processing data/partition/'2023-07-05_010000'.parquet\n",
      "\tRows: 5\n",
      "Processing data/partition/'2023-07-05_020000'.parquet\n",
      "\tRows: 5\n",
      "Processing data/partition/'2023-07-05_030000'.parquet\n",
      "\tRows: 5\n"
     ]
    }
   ],
   "source": [
    "fname_lst = []\n",
    "df = None\n",
    "\n",
    "# create a local database where queries can be run\n",
    "# you can find it under Glue in AWS Console\n",
    "wr.catalog.create_database(DATABASE, exist_ok=True)\n",
    "\n",
    "if not os.path.exists('data/partition'):\n",
    "    os.makedirs('data/partition')\n",
    "\n",
    "for idx, start_hour in enumerate(time_list):\n",
    "    output_fn = f\"data/partition/{start_hour.strftime(FILENAME_FORMAT_STR)}.parquet\"\n",
    "    print(f\"Processing {output_fn}\")\n",
    "\n",
    "    try:\n",
    "        enable_query_display = idx == 0\n",
    "        if os.path.exists(output_fn): \n",
    "            fname_lst.append(output_fn)\n",
    "            continue\n",
    "        \n",
    "        df = fetch_data(start_hour, enabled_fields_str, enable_query_display)\n",
    "        print(f\"\\tRows: {df.shape[0]:d}\")\n",
    "\n",
    "        df.to_parquet(output_fn)\n",
    "        fname_lst.append(output_fn)\n",
    "    except Exception:\n",
    "        print(f\"\\tFailed {output_fn}\")\n",
    "\n",
    "    if DEBUG and idx >= 3: break\n",
    "# end_for\n",
    "\n",
    "if df is not None: df.head(1000).to_csv('data/limit1000.csv')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"data/partition/'2023-07-05_000000'.parquet\",\n",
       " \"data/partition/'2023-07-05_010000'.parquet\",\n",
       " \"data/partition/'2023-07-05_020000'.parquet\",\n",
       " \"data/partition/'2023-07-05_030000'.parquet\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = [pd.read_parquet(fname) for fname in fname_lst]\n",
    "df_all = pd.concat(df_lst)\n",
    "df_all.to_parquet(f\"data/full-dataset_{start.strftime(FILENAME_FORMAT_STR)}_{end.strftime(FILENAME_FORMAT_STR)}.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1000).to_csv('data/limit1000.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "83893ed8ab2f7255fca62e454031b1e5cdc52831ef9a8084c39c59e4ac6d9f46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
